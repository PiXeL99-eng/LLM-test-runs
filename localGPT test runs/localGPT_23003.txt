│ ❱ 1145 │   │   return self._apply(convert)                                                       │
│   1146 │                                                                                         │
│   1147 │   def register_full_backward_pre_hook(                                                  │
│   1148 │   │   self,                                                                             │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:820 in _apply                                                                                │
│                                                                                                  │
│    817 │   │   │   # track autograd history of `param_applied`, so we have to use                │
│    818 │   │   │   # `with torch.no_grad():`                                                     │
│    819 │   │   │   with torch.no_grad():                                                         │
│ ❱  820 │   │   │   │   param_applied = fn(param)                                                 │
│    821 │   │   │   should_use_set_data = compute_should_use_set_data(param, param_applied)       │
│    822 │   │   │   if should_use_set_data:                                                       │
│    823 │   │   │   │   param.data = param_applied                                                │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:1143 in convert                                                                              │
│                                                                                                  │
│   1140 │   │   │   if convert_to_format is not None and t.dim() in (4, 5):                       │
│   1141 │   │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() els  │
│   1142 │   │   │   │   │   │   │   non_blocking, memory_format=convert_to_format)                │
│ ❱ 1143 │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() else No  │
│   1144 │   │                                                                                     │
│   1145 │   │   return self._apply(convert)                                                       │
│   1146                                                                                           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\cuda\__init__.py: │
│ 239 in _lazy_init                                                                                │
│                                                                                                  │
│    236 │   │   │   │   "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "       │
│    237 │   │   │   │   "multiprocessing, you must use the 'spawn' start method")                 │
│    238 │   │   if not hasattr(torch._C, '_cuda_getDeviceCount'):                                 │
│ ❱  239 │   │   │   raise AssertionError("Torch not compiled with CUDA enabled")                  │
│    240 │   │   if _cudart is None:                                                               │
│    241 │   │   │   raise AssertionError(                                                         │
│    242 │   │   │   │   "libcudart functions unavailable. It looks like you have a broken build?  │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
AssertionError: Torch not compiled with CUDA enabled
2023-06-30 10:23:29,268 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python run_localGPT.py
2023-06-30 10:27:10,105 - INFO - run_localGPT.py:163 - Running on: cuda
2023-06-30 10:27:10,105 - INFO - run_localGPT.py:164 - Display Source Documents set to: False
2023-06-30 10:27:10,222 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large
load INSTRUCTOR_Transformer
max_seq_length  512
2023-06-30 10:27:11,609 - INFO - __init__.py:88 - Running Chroma using direct local API.
2023-06-30 10:27:11,620 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
2023-06-30 10:27:11,735 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations
2023-06-30 10:27:11,746 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings
2023-06-30 10:27:11,766 - INFO - duckdb.py:460 - loaded in 0 embeddings
2023-06-30 10:27:11,766 - INFO - duckdb.py:472 - loaded in 1 collections
2023-06-30 10:27:11,768 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection
2023-06-30 10:27:11,768 - INFO - run_localGPT.py:45 - Loading Model: TheBloke/vicuna-7B-1.1-HF, on: cuda
2023-06-30 10:27:11,768 - INFO - run_localGPT.py:46 - This action can take a few minutes!
2023-06-30 10:27:11,769 - INFO - run_localGPT.py:73 - Using AutoModelForCausalLM for full models
Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 727/727 [00:00<?, ?B/s]
Downloading tokenizer.model: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 500k/500k [00:00<00:00, 645kB/s]
Downloading (…)cial_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 411/411 [00:00<?, ?B/s]
2023-06-30 10:28:45,727 - INFO - run_localGPT.py:75 - Tokenizer loaded
Downloading (…)lve/main/config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 582/582 [00:00<?, ?B/s]
Downloading (…)model.bin.index.json: 100%|██████████████████████████████████████████████████████████████████████████████████████| 26.8k/26.8k [00:00<?, ?B/s]
Downloading (…)l-00001-of-00002.bin: 100%|██████████████████████████████████████████████████████████████████████████████| 9.98G/9.98G [15:19<00:00, 10.8MB/s] 
Downloading (…)l-00002-of-00002.bin: 100%|██████████████████████████████████████████████████████████████████████████████| 3.50G/3.50G [10:16<00:00, 5.68MB/s] 
Downloading shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [25:36<00:00, 768.48s/it] 
2023-06-30 10:54:24,745 - WARNING - modeling.py:706 - The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.63s/it]
Downloading (…)neration_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 137/137 [00:00<?, ?B/s]
Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
2023-06-30 10:54:29,287 - INFO - run_localGPT.py:110 - Local LLM Loaded

Enter a query: What is Mobility Management Entity?
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ C:\Users\visha\OneDrive\Desktop\GenAI\localGPT\run_localGPT.py:232 in <module>                   │
│                                                                                                  │
│   229 │   logging.basicConfig(                                                                   │
│   230 │   │   format="%(asctime)s - %(levelname)s - %(filename)s:%(lineno)s - %(message)s", le   │
│   231 │   )                                                                                      │
│ ❱ 232 │   main()                                                                                 │
│   233                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1130 in   │
│ __call__                                                                                         │
│                                                                                                  │
│   1127 │                                                                                         │
│   1128 │   def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Any:                           │
│   1129 │   │   """Alias for :meth:`main`."""                                                     │
│ ❱ 1130 │   │   return self.main(*args, **kwargs)                                                 │
│   1131                                                                                           │
│   1132                                                                                           │
│   1133 class Command(BaseCommand):                                                               │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1055 in   │
│ main                                                                                             │
│                                                                                                  │
│   1052 │   │   try:                                                                              │
│   1053 │   │   │   try:                                                                          │
│   1054 │   │   │   │   with self.make_context(prog_name, args, **extra) as ctx:                  │
│ ❱ 1055 │   │   │   │   │   rv = self.invoke(ctx)                                                 │
│   1056 │   │   │   │   │   if not standalone_mode:                                               │
│   1057 │   │   │   │   │   │   return rv                                                         │
│   1058 │   │   │   │   │   # it's not safe to `ctx.exit(rv)` here!                               │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1404 in   │
│ invoke                                                                                           │
│                                                                                                  │
│   1401 │   │   │   echo(style(message, fg="red"), err=True)                                      │
│   1402 │   │                                                                                     │
│   1403 │   │   if self.callback is not None:                                                     │
│ ❱ 1404 │   │   │   return ctx.invoke(self.callback, **ctx.params)                                │
│   1405 │                                                                                         │
│   1406 │   def shell_complete(self, ctx: Context, incomplete: str) -> t.List["CompletionItem"]:  │
│   1407 │   │   """Return a list of completions for the incomplete value. Looks                   │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:760 in    │
│ invoke                                                                                           │
│                                                                                                  │
│    757 │   │                                                                                     │
│    758 │   │   with augment_usage_errors(__self):                                                │
│    759 │   │   │   with ctx:                                                                     │
│ ❱  760 │   │   │   │   return __callback(*args, **kwargs)                                        │
│    761 │                                                                                         │
│    762 │   def forward(                                                                          │
│    763 │   │   __self, __cmd: "Command", *args: t.Any, **kwargs: t.Any  # noqa: B902             │
│                                                                                                  │
│ C:\Users\visha\OneDrive\Desktop\GenAI\localGPT\run_localGPT.py:210 in main                       │
│                                                                                                  │
│   207 │   │   if query == "exit":                                                                │
│   208 │   │   │   break                                                                          │
│   209 │   │   # Get the answer from the chain                                                    │
│ ❱ 210 │   │   res = qa(query)                                                                    │
│   211 │   │   answer, docs = res["result"], res["source_documents"]                              │
│   212 │   │                                                                                      │
│   213 │   │   # Print the result                                                                 │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\base.p │
│ y:140 in __call__                                                                                │
│                                                                                                  │
│   137 │   │   │   )                                                                              │
│   138 │   │   except (KeyboardInterrupt, Exception) as e:                                        │
│   139 │   │   │   run_manager.on_chain_error(e)                                                  │
│ ❱ 140 │   │   │   raise e                                                                        │
│   141 │   │   run_manager.on_chain_end(outputs)                                                  │
│   142 │   │   return self.prep_outputs(inputs, outputs, return_only_outputs)                     │
│   143                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\base.p │
│ y:134 in __call__                                                                                │
│                                                                                                  │
│   131 │   │   )                                                                                  │
│   132 │   │   try:                                                                               │
│   133 │   │   │   outputs = (                                                                    │
│ ❱ 134 │   │   │   │   self._call(inputs, run_manager=run_manager)                                │
│   135 │   │   │   │   if new_arg_supported                                                       │
│   136 │   │   │   │   else self._call(inputs)                                                    │
│   137 │   │   │   )                                                                              │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\retrie │
│ val_qa\base.py:119 in _call                                                                      │
│                                                                                                  │
│   116 │   │   _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()        │
│   117 │   │   question = inputs[self.input_key]                                                  │
│   118 │   │                                                                                      │
│ ❱ 119 │   │   docs = self._get_docs(question)                                                    │
│   120 │   │   answer = self.combine_documents_chain.run(                                         │
│   121 │   │   │   input_documents=docs, question=question, callbacks=_run_manager.get_child()    │
│   122 │   │   )                                                                                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\retrie │
│ val_qa\base.py:181 in _get_docs                                                                  │
│                                                                                                  │
│   178 │   retriever: BaseRetriever = Field(exclude=True)                                         │
│   179 │                                                                                          │
│   180 │   def _get_docs(self, question: str) -> List[Document]:                                  │
│ ❱ 181 │   │   return self.retriever.get_relevant_documents(question)                             │
│   182 │                                                                                          │
│   183 │   async def _aget_docs(self, question: str) -> List[Document]:                           │
│   184 │   │   return await self.retriever.aget_relevant_documents(question)                      │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ base.py:376 in get_relevant_documents                                                            │
│                                                                                                  │
│   373 │                                                                                          │
│   374 │   def get_relevant_documents(self, query: str) -> List[Document]:                        │
│   375 │   │   if self.search_type == "similarity":                                               │
│ ❱ 376 │   │   │   docs = self.vectorstore.similarity_search(query, **self.search_kwargs)         │
│   377 │   │   elif self.search_type == "similarity_score_threshold":                             │
│   378 │   │   │   docs_and_similarities = (                                                      │
│   379 │   │   │   │   self.vectorstore.similarity_search_with_relevance_scores(                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ chroma.py:182 in similarity_search                                                               │
│                                                                                                  │
│   179 │   │   Returns:                                                                           │
│   180 │   │   │   List[Document]: List of documents most similar to the query text.              │
│   181 │   │   """                                                                                │
│ ❱ 182 │   │   docs_and_scores = self.similarity_search_with_score(query, k, filter=filter)       │
│   183 │   │   return [doc for doc, _ in docs_and_scores]                                         │
│   184 │                                                                                          │
│   185 │   def similarity_search_by_vector(                                                       │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ chroma.py:229 in similarity_search_with_score                                                    │
│                                                                                                  │
│   226 │   │   │   │   query_texts=[query], n_results=k, where=filter                             │
│   227 │   │   │   )                                                                              │
│   228 │   │   else:                                                                              │
│ ❱ 229 │   │   │   query_embedding = self._embedding_function.embed_query(query)                  │
│   230 │   │   │   results = self.__query_collection(                                             │
│   231 │   │   │   │   query_embeddings=[query_embedding], n_results=k, where=filter              │
│   232 │   │   │   )                                                                              │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\embeddings\hu │
│ ggingface.py:171 in embed_query                                                                  │
│                                                                                                  │
│   168 │   │   │   Embeddings for the text.                                                       │
│   169 │   │   """                                                                                │
│   170 │   │   instruction_pair = [self.query_instruction, text]                                  │
│ ❱ 171 │   │   embedding = self.client.encode([instruction_pair], **self.encode_kwargs)[0]        │
│   172 │   │   return embedding.tolist()                                                          │
│   173                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\InstructorEmbedding\ins │
│ tructor.py:521 in encode                                                                         │
│                                                                                                  │
│   518 │   │   if device is None:                                                                 │
│   519 │   │   │   device = self._target_device                                                   │
│   520 │   │                                                                                      │
│ ❱ 521 │   │   self.to(device)                                                                    │
│   522 │   │                                                                                      │
│   523 │   │   all_embeddings = []                                                                │
│   524 │   │   if isinstance(sentences[0],list):                                                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:1145 in to                                                                                   │
│                                                                                                  │
│   1142 │   │   │   │   │   │   │   non_blocking, memory_format=convert_to_format)                │
│   1143 │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() else No  │
│   1144 │   │                                                                                     │
│ ❱ 1145 │   │   return self._apply(convert)                                                       │
│   1146 │                                                                                         │
│   1147 │   def register_full_backward_pre_hook(                                                  │
│   1148 │   │   self,                                                                             │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:820 in _apply                                                                                │
│                                                                                                  │
│    817 │   │   │   # track autograd history of `param_applied`, so we have to use                │
│    818 │   │   │   # `with torch.no_grad():`                                                     │
│    819 │   │   │   with torch.no_grad():                                                         │
│ ❱  820 │   │   │   │   param_applied = fn(param)                                                 │
│    821 │   │   │   should_use_set_data = compute_should_use_set_data(param, param_applied)       │
│    822 │   │   │   if should_use_set_data:                                                       │
│    823 │   │   │   │   param.data = param_applied                                                │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:1143 in convert                                                                              │
│                                                                                                  │
│   1140 │   │   │   if convert_to_format is not None and t.dim() in (4, 5):                       │
│   1141 │   │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() els  │
│   1142 │   │   │   │   │   │   │   non_blocking, memory_format=convert_to_format)                │
│ ❱ 1143 │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() else No  │
│   1144 │   │                                                                                     │
│   1145 │   │   return self._apply(convert)                                                       │
│   1146                                                                                           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\cuda\__init__.py: │
│ 239 in _lazy_init                                                                                │
│                                                                                                  │
│    236 │   │   │   │   "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "       │
│    237 │   │   │   │   "multiprocessing, you must use the 'spawn' start method")                 │
│    238 │   │   if not hasattr(torch._C, '_cuda_getDeviceCount'):                                 │
│ ❱  239 │   │   │   raise AssertionError("Torch not compiled with CUDA enabled")                  │
│    240 │   │   if _cudart is None:                                                               │
│    241 │   │   │   raise AssertionError(                                                         │
│    242 │   │   │   │   "libcudart functions unavailable. It looks like you have a broken build?  │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
AssertionError: Torch not compiled with CUDA enabled
2023-06-30 10:59:18,614 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB      
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python3
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python
Python 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> torch.cuda.is_available()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'torch' is not defined
>>> import torch
>>> torch.cuda.is_available()
False
>>> exit
Use exit() or Ctrl-Z plus Return to exit
>>> exit()
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 
Looking in indexes: https://download.pytorch.org/whl/cu117
Requirement already satisfied: torch in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.1)
Requirement already satisfied: torchvision in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (0.15.2)
Requirement already satisfied: torchaudio in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.2+cu117)
Requirement already satisfied: filelock in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.12.2)
Requirement already satisfied: typing-extensions in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (4.7.0)
Requirement already satisfied: sympy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (1.12)
Requirement already satisfied: networkx in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1.2)
Requirement already satisfied: numpy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (1.23.5)
Requirement already satisfied: requests in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (2.31.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (9.5.0)   
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.4)    
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (1.26.6)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (2023.5.7)
Requirement already satisfied: mpmath>=0.19 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from sympy->torch) (1.3.0)
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
Looking in indexes: https://download.pytorch.org/whl/cu118
Requirement already satisfied: torch in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.1)
Requirement already satisfied: torchvision in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (0.15.2)
Requirement already satisfied: torchaudio in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.2+cu117)
Requirement already satisfied: filelock in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.12.2)
Requirement already satisfied: typing-extensions in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (4.7.0)
Requirement already satisfied: sympy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (1.12)
Requirement already satisfied: networkx in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1.2)
Requirement already satisfied: numpy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (1.23.5)
Requirement already satisfied: requests in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (2.31.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (9.5.0)   
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.4)    
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (1.26.6)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (2023.5.7)
Requirement already satisfied: mpmath>=0.19 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from sympy->torch) (1.3.0)
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 
Looking in indexes: https://download.pytorch.org/whl/cu118
Requirement already satisfied: torch in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.1)
Requirement already satisfied: torchvision in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (0.15.2)
Requirement already satisfied: torchaudio in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (2.0.2+cu117)
Requirement already satisfied: filelock in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.12.2)
Requirement already satisfied: typing-extensions in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (4.7.0)
Requirement already satisfied: sympy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (1.12)
Requirement already satisfied: networkx in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1.2)
Requirement already satisfied: numpy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (1.23.5)
Requirement already satisfied: requests in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (2.31.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (9.5.0)   
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (1.26.6)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (2023.5.7)
Requirement already satisfied: mpmath>=0.19 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from sympy->torch) (1.3.0)
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python                                                                                      
Python 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> torch.cuda.is_available()
False
>>> exit()
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> nvidia-smi.exe
Fri Jun 30 11:08:51 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3080       WDDM | 00000000:01:00.0  On |                  N/A |
|  0%   36C    P8               23W / 320W|    668MiB / 10240MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      2016    C+G   C:\Windows\System32\dwm.exe               N/A      |
|    0   N/A  N/A      2512    C+G   ...siveControlPanel\SystemSettings.exe    N/A      |
|    0   N/A  N/A      3136    C+G   ....5790.10\remote_assistance_host.exe    N/A      |
|    0   N/A  N/A      4292    C+G   ...on\114.0.1823.58\msedgewebview2.exe    N/A      |
|    0   N/A  N/A      4532    C+G   C:\Windows\explorer.exe                   N/A      |
|    0   N/A  N/A      6684    C+G   ...crosoft\Edge\Application\msedge.exe    N/A      |
|    0   N/A  N/A      6888    C+G   ...nt.CBS_cw5n1h2txyewy\SearchHost.exe    N/A      |
|    0   N/A  N/A      6912    C+G   ...2txyewy\StartMenuExperienceHost.exe    N/A      |
|    0   N/A  N/A      8720    C+G   ...5n1h2txyewy\ShellExperienceHost.exe    N/A      |
|    0   N/A  N/A     12100    C+G   ...on\114.0.1823.58\msedgewebview2.exe    N/A      |
|    0   N/A  N/A     12620    C+G   ...cal\Microsoft\OneDrive\OneDrive.exe    N/A      |
|    0   N/A  N/A     16288    C+G   ...GeForce Experience\NVIDIA Share.exe    N/A      |
|    0   N/A  N/A     16668    C+G   ...03.0_x64__8wekyb3d8bbwe\Cortana.exe    N/A      |
|    0   N/A  N/A     21108    C+G   ...on\114.0.1823.58\msedgewebview2.exe    N/A      |
|    0   N/A  N/A     22332    C+G   ...amsung Magician\SamsungMagician.exe    N/A      |
|    0   N/A  N/A     22356    C+G   ...Programs\Microsoft VS Code\Code.exe    N/A      |
|    0   N/A  N/A     23020    C+G   ...CBS_cw5n1h2txyewy\TextInputHost.exe    N/A      |
+---------------------------------------------------------------------------------------+
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip list | findstr torch
torch                   2.0.1
torchaudio              2.0.2+cu117
torchvision             0.15.2
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip uninstall torch torchvision torchaudio
>> pip cache purge
>> pip list | findstr torch
Found existing installation: torch 2.0.1
Uninstalling torch-2.0.1:
  Would remove:
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\functorch\*
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torch-2.0.1.dist-info\*
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torch\*
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torchgen\*
    c:\users\visha\appdata\local\programs\python\python311\scripts\convert-caffe2-to-onnx.exe
    c:\users\visha\appdata\local\programs\python\python311\scripts\convert-onnx-to-caffe2.exe
    c:\users\visha\appdata\local\programs\python\python311\scripts\torchrun.exe
Proceed (Y/n)? Y
  Successfully uninstalled torch-2.0.1
Found existing installation: torchvision 0.15.2
Uninstalling torchvision-0.15.2:
  Would remove:
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torchvision-0.15.2.dist-info\*
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torchvision\*
Proceed (Y/n)? Y
  Successfully uninstalled torchvision-0.15.2
Found existing installation: torchaudio 2.0.2+cu117
Uninstalling torchaudio-2.0.2+cu117:
  Would remove:
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torchaudio-2.0.2+cu117.dist-info\*
    c:\users\visha\appdata\local\programs\python\python311\lib\site-packages\torchaudio\*
Proceed (Y/n)? Y
  Successfully uninstalled torchaudio-2.0.2+cu117
Files removed: 331
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
Looking in indexes: https://download.pytorch.org/whl/cu117
Collecting torch
  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.1%2Bcu117-cp311-cp311-win_amd64.whl (2343.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 GB 2.6 MB/s eta 0:00:00
Collecting torchvision
  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.15.2%2Bcu117-cp311-cp311-win_amd64.whl (4.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 1.2 MB/s eta 0:00:00
Collecting torchaudio
  Downloading https://download.pytorch.org/whl/cu117/torchaudio-2.0.2%2Bcu117-cp311-cp311-win_amd64.whl (2.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 1.7 MB/s eta 0:00:00
Requirement already satisfied: filelock in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.12.2)
Requirement already satisfied: typing-extensions in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (4.7.0)
Requirement already satisfied: sympy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (1.12)
Requirement already satisfied: networkx in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torch) (3.1.2)
Requirement already satisfied: numpy in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (1.23.5)
Requirement already satisfied: requests in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (2.31.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from torchvision) (9.5.0)   
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from jinja2->torch) (2.1.3)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (3.4)    
Requirement already satisfied: urllib3<3,>=1.21.1 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (1.26.6)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from requests->torchvision) (2023.5.7)
Requirement already satisfied: mpmath>=0.19 in c:\users\visha\appdata\local\programs\python\python311\lib\site-packages (from sympy->torch) (1.3.0)
Installing collected packages: torch, torchvision, torchaudio
Successfully installed torch-2.0.1+cu117 torchaudio-2.0.2+cu117 torchvision-0.15.2+cu117
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> pip list | findstr torch
torch                   2.0.1+cu117
torchaudio              2.0.2+cu117
torchvision             0.15.2+cu117
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python -c 'import torch; print(torch.cuda.is_available())'
True
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python ingest.py  # defaults to cuda
2023-06-30 11:19:46,414 - INFO - ingest.py:120 - Loading documents from C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/SOURCE_DOCUMENTS
2023-06-30 11:19:50,989 - INFO - ingest.py:129 - Loaded 1 documents from C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/SOURCE_DOCUMENTS
2023-06-30 11:19:50,989 - INFO - ingest.py:130 - Split into 566 chunks of text
2023-06-30 11:19:52,732 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large
load INSTRUCTOR_Transformer
max_seq_length  512
2023-06-30 11:19:54,399 - INFO - __init__.py:88 - Running Chroma using direct local API.
2023-06-30 11:19:54,619 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
2023-06-30 11:19:54,627 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations
2023-06-30 11:19:54,633 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings
2023-06-30 11:19:54,657 - INFO - duckdb.py:460 - loaded in 0 embeddings
2023-06-30 11:19:54,657 - INFO - duckdb.py:472 - loaded in 1 collections
2023-06-30 11:19:54,658 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection
2023-06-30 11:20:07,328 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
2023-06-30 11:20:07,374 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python run_localGPT.py                                                                                     
2023-06-30 11:21:37,800 - INFO - run_localGPT.py:163 - Running on: cuda
2023-06-30 11:21:37,800 - INFO - run_localGPT.py:164 - Display Source Documents set to: False
2023-06-30 11:21:37,922 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large
load INSTRUCTOR_Transformer
max_seq_length  512
2023-06-30 11:21:39,472 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
2023-06-30 11:21:39,482 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations
2023-06-30 11:21:39,485 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings
2023-06-30 11:21:39,515 - INFO - duckdb.py:460 - loaded in 566 embeddings
2023-06-30 11:21:39,516 - INFO - duckdb.py:472 - loaded in 1 collections
2023-06-30 11:21:39,517 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection
2023-06-30 11:21:39,517 - INFO - run_localGPT.py:45 - Loading Model: TheBloke/vicuna-7B-1.1-HF, on: cuda
2023-06-30 11:21:39,517 - INFO - run_localGPT.py:46 - This action can take a few minutes!
2023-06-30 11:21:39,517 - INFO - run_localGPT.py:73 - Using AutoModelForCausalLM for full models
2023-06-30 11:23:08,826 - INFO - run_localGPT.py:75 - Tokenizer loaded
2023-06-30 11:23:09,297 - WARNING - modeling.py:706 - The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.16s/it]
Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
2023-06-30 11:23:16,250 - INFO - run_localGPT.py:110 - Local LLM Loaded

Enter a query: What is Mobile Management Entity?
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ C:\Users\visha\OneDrive\Desktop\GenAI\localGPT\run_localGPT.py:232 in <module>                   │
│                                                                                                  │
│   229 │   logging.basicConfig(                                                                   │
│   230 │   │   format="%(asctime)s - %(levelname)s - %(filename)s:%(lineno)s - %(message)s", le   │
│   231 │   )                                                                                      │
│ ❱ 232 │   main()                                                                                 │
│   233                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1130 in   │
│ __call__                                                                                         │
│                                                                                                  │
│   1127 │                                                                                         │
│   1128 │   def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Any:                           │
│   1129 │   │   """Alias for :meth:`main`."""                                                     │
│ ❱ 1130 │   │   return self.main(*args, **kwargs)                                                 │
│   1131                                                                                           │
│   1132                                                                                           │
│   1133 class Command(BaseCommand):                                                               │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1055 in   │
│ main                                                                                             │
│                                                                                                  │
│   1052 │   │   try:                                                                              │
│   1053 │   │   │   try:                                                                          │
│   1054 │   │   │   │   with self.make_context(prog_name, args, **extra) as ctx:                  │
│ ❱ 1055 │   │   │   │   │   rv = self.invoke(ctx)                                                 │
│   1056 │   │   │   │   │   if not standalone_mode:                                               │
│   1057 │   │   │   │   │   │   return rv                                                         │
│   1058 │   │   │   │   │   # it's not safe to `ctx.exit(rv)` here!                               │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:1404 in   │
│ invoke                                                                                           │
│                                                                                                  │
│   1401 │   │   │   echo(style(message, fg="red"), err=True)                                      │
│   1402 │   │                                                                                     │
│   1403 │   │   if self.callback is not None:                                                     │
│ ❱ 1404 │   │   │   return ctx.invoke(self.callback, **ctx.params)                                │
│   1405 │                                                                                         │
│   1406 │   def shell_complete(self, ctx: Context, incomplete: str) -> t.List["CompletionItem"]:  │
│   1407 │   │   """Return a list of completions for the incomplete value. Looks                   │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\click\core.py:760 in    │
│ invoke                                                                                           │
│                                                                                                  │
│    757 │   │                                                                                     │
│    758 │   │   with augment_usage_errors(__self):                                                │
│    759 │   │   │   with ctx:                                                                     │
│ ❱  760 │   │   │   │   return __callback(*args, **kwargs)                                        │
│    761 │                                                                                         │
│    762 │   def forward(                                                                          │
│    763 │   │   __self, __cmd: "Command", *args: t.Any, **kwargs: t.Any  # noqa: B902             │
│                                                                                                  │
│ C:\Users\visha\OneDrive\Desktop\GenAI\localGPT\run_localGPT.py:210 in main                       │
│                                                                                                  │
│   207 │   │   if query == "exit":                                                                │
│   208 │   │   │   break                                                                          │
│   209 │   │   # Get the answer from the chain                                                    │
│ ❱ 210 │   │   res = qa(query)                                                                    │
│   211 │   │   answer, docs = res["result"], res["source_documents"]                              │
│   212 │   │                                                                                      │
│   213 │   │   # Print the result                                                                 │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\base.p │
│ y:140 in __call__                                                                                │
│                                                                                                  │
│   137 │   │   │   )                                                                              │
│   138 │   │   except (KeyboardInterrupt, Exception) as e:                                        │
│   139 │   │   │   run_manager.on_chain_error(e)                                                  │
│ ❱ 140 │   │   │   raise e                                                                        │
│   141 │   │   run_manager.on_chain_end(outputs)                                                  │
│   142 │   │   return self.prep_outputs(inputs, outputs, return_only_outputs)                     │
│   143                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\base.p │
│ y:134 in __call__                                                                                │
│                                                                                                  │
│   131 │   │   )                                                                                  │
│   132 │   │   try:                                                                               │
│   133 │   │   │   outputs = (                                                                    │
│ ❱ 134 │   │   │   │   self._call(inputs, run_manager=run_manager)                                │
│   135 │   │   │   │   if new_arg_supported                                                       │
│   136 │   │   │   │   else self._call(inputs)                                                    │
│   137 │   │   │   )                                                                              │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\retrie │
│ val_qa\base.py:119 in _call                                                                      │
│                                                                                                  │
│   116 │   │   _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()        │
│   117 │   │   question = inputs[self.input_key]                                                  │
│   118 │   │                                                                                      │
│ ❱ 119 │   │   docs = self._get_docs(question)                                                    │
│   120 │   │   answer = self.combine_documents_chain.run(                                         │
│   121 │   │   │   input_documents=docs, question=question, callbacks=_run_manager.get_child()    │
│   122 │   │   )                                                                                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\chains\retrie │
│ val_qa\base.py:181 in _get_docs                                                                  │
│                                                                                                  │
│   178 │   retriever: BaseRetriever = Field(exclude=True)                                         │
│   179 │                                                                                          │
│   180 │   def _get_docs(self, question: str) -> List[Document]:                                  │
│ ❱ 181 │   │   return self.retriever.get_relevant_documents(question)                             │
│   182 │                                                                                          │
│   183 │   async def _aget_docs(self, question: str) -> List[Document]:                           │
│   184 │   │   return await self.retriever.aget_relevant_documents(question)                      │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ base.py:376 in get_relevant_documents                                                            │
│                                                                                                  │
│   373 │                                                                                          │
│   374 │   def get_relevant_documents(self, query: str) -> List[Document]:                        │
│   375 │   │   if self.search_type == "similarity":                                               │
│ ❱ 376 │   │   │   docs = self.vectorstore.similarity_search(query, **self.search_kwargs)         │
│   377 │   │   elif self.search_type == "similarity_score_threshold":                             │
│   378 │   │   │   docs_and_similarities = (                                                      │
│   379 │   │   │   │   self.vectorstore.similarity_search_with_relevance_scores(                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ chroma.py:182 in similarity_search                                                               │
│                                                                                                  │
│   179 │   │   Returns:                                                                           │
│   180 │   │   │   List[Document]: List of documents most similar to the query text.              │
│   181 │   │   """                                                                                │
│ ❱ 182 │   │   docs_and_scores = self.similarity_search_with_score(query, k, filter=filter)       │
│   183 │   │   return [doc for doc, _ in docs_and_scores]                                         │
│   184 │                                                                                          │
│   185 │   def similarity_search_by_vector(                                                       │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\vectorstores\ │
│ chroma.py:229 in similarity_search_with_score                                                    │
│                                                                                                  │
│   226 │   │   │   │   query_texts=[query], n_results=k, where=filter                             │
│   227 │   │   │   )                                                                              │
│   228 │   │   else:                                                                              │
│ ❱ 229 │   │   │   query_embedding = self._embedding_function.embed_query(query)                  │
│   230 │   │   │   results = self.__query_collection(                                             │
│   231 │   │   │   │   query_embeddings=[query_embedding], n_results=k, where=filter              │
│   232 │   │   │   )                                                                              │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain\embeddings\hu │
│ ggingface.py:171 in embed_query                                                                  │
│                                                                                                  │
│   168 │   │   │   Embeddings for the text.                                                       │
│   169 │   │   """                                                                                │
│   170 │   │   instruction_pair = [self.query_instruction, text]                                  │
│ ❱ 171 │   │   embedding = self.client.encode([instruction_pair], **self.encode_kwargs)[0]        │
│   172 │   │   return embedding.tolist()                                                          │
│   173                                                                                            │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\InstructorEmbedding\ins │
│ tructor.py:521 in encode                                                                         │
│                                                                                                  │
│   518 │   │   if device is None:                                                                 │
│   519 │   │   │   device = self._target_device                                                   │
│   520 │   │                                                                                      │
│ ❱ 521 │   │   self.to(device)                                                                    │
│   522 │   │                                                                                      │
│   523 │   │   all_embeddings = []                                                                │
│   524 │   │   if isinstance(sentences[0],list):                                                  │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:1145 in to                                                                                   │
│                                                                                                  │
│   1142 │   │   │   │   │   │   │   non_blocking, memory_format=convert_to_format)                │
│   1143 │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() else No  │
│   1144 │   │                                                                                     │
│ ❱ 1145 │   │   return self._apply(convert)                                                       │
│   1146 │                                                                                         │
│   1147 │   def register_full_backward_pre_hook(                                                  │
│   1148 │   │   self,                                                                             │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:797 in _apply                                                                                │
│                                                                                                  │
│    794 │                                                                                         │
│    795 │   def _apply(self, fn):                                                                 │
│    796 │   │   for module in self.children():                                                    │
│ ❱  797 │   │   │   module._apply(fn)                                                             │
│    798 │   │                                                                                     │
│    799 │   │   def compute_should_use_set_data(tensor, tensor_applied):                          │
│    800 │   │   │   if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:820 in _apply                                                                                │
│                                                                                                  │
│    817 │   │   │   # track autograd history of `param_applied`, so we have to use                │
│    818 │   │   │   # `with torch.no_grad():`                                                     │
│    819 │   │   │   with torch.no_grad():                                                         │
│ ❱  820 │   │   │   │   param_applied = fn(param)                                                 │
│    821 │   │   │   should_use_set_data = compute_should_use_set_data(param, param_applied)       │
│    822 │   │   │   if should_use_set_data:                                                       │
│    823 │   │   │   │   param.data = param_applied                                                │
│                                                                                                  │
│ C:\Users\visha\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module │
│ .py:1143 in convert                                                                              │
│                                                                                                  │
│   1140 │   │   │   if convert_to_format is not None and t.dim() in (4, 5):                       │
│   1141 │   │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() els  │
│   1142 │   │   │   │   │   │   │   non_blocking, memory_format=convert_to_format)                │
│ ❱ 1143 │   │   │   return t.to(device, dtype if t.is_floating_point() or t.is_complex() else No  │
│   1144 │   │                                                                                     │
│   1145 │   │   return self._apply(convert)                                                       │
│   1146                                                                                           │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.00 GiB total capacity; 9.28 GiB already allocated; 0 bytes free; 9.29 GiB     
reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory
Management and PYTORCH_CUDA_ALLOC_CONF
2023-06-30 11:23:37,008 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB   
PS C:\Users\visha\OneDrive\Desktop\GenAI\localGPT> python run_localGPT.py --device_type cpu
2023-06-30 11:25:22,375 - INFO - run_localGPT.py:163 - Running on: cpu
2023-06-30 11:25:22,375 - INFO - run_localGPT.py:164 - Display Source Documents set to: False
2023-06-30 11:25:22,500 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large
load INSTRUCTOR_Transformer
max_seq_length  512
2023-06-30 11:25:23,910 - INFO - __init__.py:88 - Running Chroma using direct local API.
2023-06-30 11:25:24,025 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: C:\Users\visha\OneDrive\Desktop\GenAI\localGPT/DB
2023-06-30 11:25:24,038 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations
2023-06-30 11:25:24,042 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings
2023-06-30 11:25:24,073 - INFO - duckdb.py:460 - loaded in 566 embeddings
2023-06-30 11:25:24,074 - INFO - duckdb.py:472 - loaded in 1 collections
2023-06-30 11:25:24,075 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection
2023-06-30 11:25:24,075 - INFO - run_localGPT.py:45 - Loading Model: TheBloke/vicuna-7B-1.1-HF, on: cpu
2023-06-30 11:25:24,076 - INFO - run_localGPT.py:46 - This action can take a few minutes!
2023-06-30 11:25:24,076 - INFO - run_localGPT.py:87 - Using LlamaTokenizer
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:40<00:00, 50.13s/it]
Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
2023-06-30 11:27:27,962 - INFO - run_localGPT.py:110 - Local LLM Loaded

Enter a query: What is mobile mobile management entity?


> Question:
What is mobile mobile management entity?

> Answer:
 A Mobility Management Entity (MME) is a component responsible for managing the mobility of User Equipments (UEs) in a cellular communication system such as 3GPP. It performs functions like authentication, charging, and control plane signaling.

Enter a query: What does GUTI stand for?


> Question:
What does GUTI stand for?

> Answer:
 Globally Unique Temporary UE Identity

Enter a query: Explain SUPI.


> Question:
Explain SUPI.

> Answer:
 A SUPI is a globally unique 5G Subscription Permanent Identifier allocated to each subscriber in the 5G System. It is defined as a SUPI type followed by an identifier depending on the value of the SUPI type. The SUPI type can be an IMSI, a network specific identifier, a GLI or a GCI. The SUPI is used to identify subscribers across networks and services, and to enable secure communication between devices and servers.

Enter a query: Explain SUCI.


> Question:
Explain SUCI.

> Answer:
 Subscriber Unit Identity Compartment (SUIC) is a security feature introduced in 3GPP Release 6 which allows multiple identities to be associated with a single device. Each identity can have its own set of services and features, allowing users to switch between them as needed without having to change their phone number or SIM card. The SUIC is implemented using a concept called "subscription unit" (SU). A subscription unit is identified by a unique identifier called the Subscription Concealed Identifier (SUCI). The SUCI consists of several components including the SUPI Type, which identifies the type of SUPI concealed within the SUCI, and the Home Network Identifier, which identifies the home network of the subscriber. When the SUPI Type is an IMSI, the Home Network Identifier is further divided into two parts: the Mobile Country Code (MCC) and the Mobile Network Code (MNC).

Enter a query: What is SUCI composed of?


> Question:
What is SUCI composed of?

> Answer:
 SUCI stands for Subscription Concealed Identifier and it is composed of several parts including a SUPI Type which identifies the type of the SUPI concealed in the SUCI and a Home Network Identifier which identifies the home network of the subscriber.

Enter a query: What does AMF stand for?  


> Question:
What does AMF stand for?

> Answer:
 The acronym "AMF" stands for "Application Messaging Facility".

Enter a query: What does AMF stand for according to 3GPP? 


> Question:
What does AMF stand for according to 3GPP?

> Answer:
 According to 3GPP, AMF stands for Application Management Function.

Enter a query: Explan MME 


> Question:
Explan MME

> Answer:
 The MME (Mobility Management Entity) is responsible for managing the mobility of UEs in a network. It performs functions such as authentication, ciphering, paging, tracking and control of the serving cell.

Enter a query: What is IMSI composed of?


> Question:
What is IMSI composed of?

> Answer:
 IMSI stands for International Mobile Subscriber Identity and it is composed of three parts: Mobile Country Code (MCC), Mobile Network Code (MNC), and the Mobile Station Integrated Services Digital Network (ISDN) number (MSIN).